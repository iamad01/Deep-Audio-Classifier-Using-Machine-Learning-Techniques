{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.distribute.distribution_strategy_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MobileNetV2\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmobilenet_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_input\n",
      "File \u001b[1;32mc:\\Users\\soume\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py:45\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\soume\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "File \u001b[1;32mc:\\Users\\soume\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribution_strategy_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variable_sync_on_read_context\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge_call_interim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m strategy_supports_no_merge_call\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msharded_variable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShardedVariable\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.distribute.distribution_strategy_context'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import sounddevice as sd\n",
    "import wave\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import plotly.graph_objects as go\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import base64\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class AudioSpectrogramClassifier:\n",
    "    def __init__(self, data_dirs, spectrogram_dir, model_save_path='audio_classifier.pkl'):\n",
    "        self.data_dirs = data_dirs\n",
    "        self.spectrogram_dir = spectrogram_dir\n",
    "        self.model_save_path = model_save_path\n",
    "        self.feature_extractor = self._initialize_feature_extractor()\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
    "        self.clf = None\n",
    "        self.train_accuracy = []\n",
    "        self.test_accuracy = []\n",
    "        self.f1_scores = []\n",
    "        self.epochs = []\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self._create_spectrogram_directory()\n",
    "\n",
    "    def _initialize_feature_extractor(self):\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
    "        for layer in base_model.layers[:-10]:  # Fine-tune last 10 layers\n",
    "            layer.trainable = True\n",
    "        return Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "    def _create_spectrogram_directory(self):\n",
    "        if not os.path.exists(self.spectrogram_dir):\n",
    "            os.makedirs(self.spectrogram_dir)\n",
    "\n",
    "    def _load_audio(self, audio_path, sr=22050):\n",
    "        try:\n",
    "            if not os.path.isfile(audio_path):\n",
    "                logging.error(f\"Audio path is not a file: {audio_path}\")\n",
    "                return None, sr\n",
    "            y, sr = librosa.load(audio_path, sr=sr, mono=True)\n",
    "            return y, sr\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading audio {audio_path}: {e}\")\n",
    "            return None, sr\n",
    "\n",
    "    def audio_to_spectrogram(self, audio_path, sr=22050):\n",
    "        y, sr = self._load_audio(audio_path, sr)\n",
    "        if y is None:\n",
    "            return None\n",
    "        spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        log_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "        return log_spectrogram\n",
    "\n",
    "    def save_spectrogram(self, spectrogram, filename):\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        librosa.display.specshow(spectrogram, sr=22050, x_axis='time', y_axis='mel')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(filename, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "    def extract_features(self, img_path):\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        features = self.feature_extractor.predict(x)\n",
    "        return features.flatten()\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        for label, data_dir in self.data_dirs.items():\n",
    "            if not os.path.isdir(data_dir):\n",
    "                logging.error(f\"Data directory is not valid: {data_dir}\")\n",
    "                continue\n",
    "            audio_files = os.listdir(data_dir)\n",
    "            logging.info(f\"Found audio files in {data_dir}: {audio_files}\")\n",
    "            for audio_file in audio_files:\n",
    "                audio_path = os.path.join(data_dir, audio_file)\n",
    "                if audio_file.lower().endswith(('.wav', '.mp3', '.flac')):\n",
    "                    logging.info(f\"Processing audio file: {audio_path}\")\n",
    "                    spectrogram = self.audio_to_spectrogram(audio_path)\n",
    "                    if spectrogram is not None:\n",
    "                        spectrogram_filename = os.path.join(self.spectrogram_dir, f\"{label}_{audio_file}.png\")\n",
    "                        self.save_spectrogram(spectrogram, spectrogram_filename)\n",
    "                        feature_vector = self.extract_features(spectrogram_filename)\n",
    "                        self.features.append(feature_vector)\n",
    "                        self.labels.append(label)\n",
    "                    else:\n",
    "                        logging.warning(f\"Spectrogram generation failed for {audio_path}. Skipping.\")\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            np.array(self.features),\n",
    "            np.array(self.labels),\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    def train_classifier(self, epochs=5, use_xgboost=False, use_svm=False):\n",
    "        self.prepare_dataset()\n",
    "\n",
    "        if use_xgboost:\n",
    "            self.clf = XGBClassifier(random_state=42, reg_alpha=0.1, reg_lambda=0.1)  # Add regularization\n",
    "            param_grid = {\n",
    "                'n_estimators': [50, 100, 150],\n",
    "                'max_depth': [3, 6, 9],\n",
    "                'learning_rate': [0.01, 0.1, 0.2]\n",
    "            }\n",
    "            self.clf = GridSearchCV(self.clf, param_grid, cv=3, scoring='accuracy')\n",
    "        elif use_svm:\n",
    "            self.clf = SVC(probability=True, random_state=42, C=1.0, kernel='rbf')  # Regularization parameter\n",
    "        else:\n",
    "            self.clf = RandomForestClassifier(\n",
    "                n_estimators=100, max_depth=10, min_samples_split=4,\n",
    "                random_state=42, class_weight='balanced'\n",
    "            )\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            self.clf.fit(self.X_train, self.y_train)\n",
    "            y_train_pred = self.clf.predict(self.X_train)\n",
    "            y_test_pred = self.clf.predict(self.X_test)\n",
    "\n",
    "            train_acc = accuracy_score(self.y_train, y_train_pred)\n",
    "            test_acc = accuracy_score(self.y_test, y_test_pred)\n",
    "            f1 = f1_score(self.y_test, y_test_pred, average='weighted')\n",
    "\n",
    "            self.train_accuracy.append(train_acc)\n",
    "            self.test_accuracy.append(test_acc)\n",
    "            self.f1_scores.append(f1)\n",
    "            self.epochs.append(epoch)\n",
    "\n",
    "            logging.info(f\"Epoch {epoch}: Train Acc={train_acc}, Test Acc={test_acc}, F1={f1}\")\n",
    "\n",
    "            # Early stopping condition\n",
    "            if epoch > 1 and test_acc < self.test_accuracy[-2]:\n",
    "                logging.info(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        joblib.dump(self.clf, self.model_save_path)\n",
    "        logging.info(f\"Model trained and saved to {self.model_save_path}\")\n",
    "\n",
    "    def plot_training_metrics(self):\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=self.epochs, y=self.train_accuracy, mode='lines+markers', name=\"Train Accuracy\"))\n",
    "        fig.add_trace(go.Scatter(x=self.epochs, y=self.test_accuracy, mode='lines+markers', name=\"Test Accuracy\"))\n",
    "        fig.add_trace(go.Scatter(x=self.epochs, y=self.f1_scores, mode='lines+markers', name=\"F1 Score\"))\n",
    "        fig.update_layout(title=\"Model Training Metrics Over Epochs\", xaxis_title=\"Epochs\", yaxis_title=\"Metrics\")\n",
    "        return fig\n",
    "\n",
    "    def plot_audio_waveform(self, audio_path):\n",
    "        y, sr = self._load_audio(audio_path)\n",
    "        if y is None:\n",
    "            return go.Figure()  # Return an empty figure if audio loading failed\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=np.arange(len(y)) / sr, y=y, mode='lines', name=\"Waveform\"))\n",
    "        fig.update_layout(title=\"Audio Waveform\", xaxis_title=\"Time (s)\", yaxis_title=\"Amplitude\")\n",
    "        return fig\n",
    "\n",
    "    def plot_audio_spectrogram(self, audio_path):\n",
    "        y, sr = self._load_audio(audio_path)\n",
    "        if y is None:\n",
    "            return go.Figure()  # Return an empty figure if audio loading failed\n",
    "        spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        log_spectrogram = librosa.power_to_db(spectrogram , ref=np.max)\n",
    "        fig = go.Figure(data=go.Heatmap(z=log_spectrogram, colorscale=\"Viridis\"))\n",
    "        fig.update_layout(title=\"Mel Spectrogram\", xaxis_title=\"Time\", yaxis_title=\"Frequency\")\n",
    "        return fig\n",
    "\n",
    "    def plot_confusion_matrix(self):\n",
    "        y_pred = self.clf.predict(self.X_test)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        fig = go.Figure(data=go.Heatmap(z=cm, colorscale='Blues',\n",
    "                                          x=['Predicted: ' + str(i) for i in self.label_encoder.classes_],\n",
    "                                          y=['True: ' + str(i) for i in self.label_encoder.classes_], \n",
    "                                          hoverinfo='z+text', text=cm, showscale=True))\n",
    "        fig.update_layout(title='Confusion Matrix', xaxis_title='Predicted Label', yaxis_title='True Label')\n",
    "\n",
    "        # Add annotations to the confusion matrix\n",
    "        for i in range(len(cm)):\n",
    "            for j in range(len(cm)):\n",
    "                fig.add_annotation(\n",
    "                    x=j,\n",
    "                    y=i,\n",
    "                    text=str(cm[i, j]),\n",
    "                    showarrow=False,\n",
    "                    font=dict(color='white' if cm[i, j] > cm.max() / 2 else 'black')\n",
    "                )\n",
    "        return fig\n",
    "\n",
    "    def plot_feature_importance(self):\n",
    "        if hasattr(self.clf, 'feature_importances_'):\n",
    "            importances = self.clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Bar(\n",
    "                x=importances[indices],\n",
    "                y=[f'Feature {i+1}' for i in indices],\n",
    "                orientation='h'\n",
    "            ))\n",
    "            fig.update_layout(title='Feature Importance', xaxis_title='Importance', yaxis_title='Features')\n",
    "            return fig\n",
    "        else:\n",
    "            logging.warning(\"The classifier does not have feature importances.\")\n",
    "            return go.Figure()  # Return an empty figure or a message indicating no importances\n",
    "\n",
    "    def plot_training_data_distribution(self):\n",
    "        label_counts = np.bincount(self.y_train)\n",
    "        fig = go.Figure(data=go.Bar(\n",
    "            x=self.label_encoder.classes_,\n",
    "            y=label_counts\n",
    "        ))\n",
    "        fig.update_layout(title='Training Data Distribution', xaxis_title='Classes', yaxis_title='Number of Samples')\n",
    "        return fig\n",
    "\n",
    "    def plot_feature_distribution(self):\n",
    "        if self.X_train is not None:\n",
    "            fig = go.Figure()\n",
    "            for i in range(self.X_train.shape[1]):\n",
    "                fig.add_trace(go.Histogram(x=self.X_train[:, i], name=f'Feature {i+1}', opacity=0.75))\n",
    "            fig.update_layout(title='Feature Distribution', xaxis_title='Feature Value', yaxis_title='Count')\n",
    "            return fig\n",
    "        else:\n",
    "            logging.warning(\"Training data is not available for feature distribution.\")\n",
    "            return go.Figure()\n",
    "\n",
    "    def predict_bird_count(self, audio_path):\n",
    "        y, sr = self._load_audio(audio_path)\n",
    "        if y is None:\n",
    "            logging.error(\"Audio loading failed.\")\n",
    "            return \"Error loading audio file.\"\n",
    "        \n",
    "        # Segment the audio into 5-second chunks\n",
    "        segment_duration = 5  # seconds\n",
    "        segment_samples = segment_duration * sr\n",
    "        bird_predictions = []\n",
    "\n",
    "        for start in range(0, len(y), segment_samples):\n",
    "            end = min(start + segment_samples, len(y))\n",
    "            segment = y[start:end]\n",
    "            if len(segment) == 0:\n",
    "                continue  # Skip empty segments\n",
    "            spectrogram = self.audio_to_spectrogram(audio_path)  # Use the original audio path\n",
    "            if spectrogram is not None:\n",
    "                spectrogram_filename = \"temp_spectrogram.png\"\n",
    "                self.save_spectrogram(spectrogram, spectrogram_filename)\n",
    "                feature_vector = self.extract_features(spectrogram_filename)\n",
    "                prediction = self.clf.predict(np.array([feature_vector]))\n",
    "                predicted_label = self.label_encoder.inverse_transform(prediction)\n",
    "                timestamp = start / sr  # Convert sample index to time in seconds\n",
    "                bird_predictions.append((predicted_label[0], timestamp))  # Store the prediction and timestamp\n",
    "\n",
    "        return bird_predictions\n",
    "\n",
    "    def record_audio(self, duration=5, filename='live_recording.wav'):\n",
    "        \"\"\"Record audio from the microphone.\"\"\"\n",
    "        logging.info(f\"Recording audio for {duration} seconds...\")\n",
    "        fs = 44100  # Sample rate\n",
    "        recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float64')\n",
    "        sd.wait()  # Wait until recording is finished\n",
    "        # Save the recording as a WAV file\n",
    "        with wave.open(filename, 'wb') as wf:\n",
    "            wf.setnchannels(1)\n",
    "            wf.setsampwidth(2)  # ```python\n",
    "            wf.setframerate(fs)\n",
    "            wf.writeframes((recording * 32767).astype(np.int16))  # Convert to 16-bit PCM\n",
    "        logging.info(f\"Recording saved to {filename}\")\n",
    "\n",
    "# Define data directories and spectrogram directory\n",
    "data_dirs = {\n",
    "    'Capuchin bird': r'C:\\Users\\soume\\OneDrive\\Documents\\WORK M\\Capuchin bird', \n",
    "    'Thryomanes bewickii': r'C:\\Users\\soume\\OneDrive\\Documents\\WORK M\\Thryomanes  bewickii',\n",
    "    'Pomatorhinus ruficollis': r'C:\\Users\\soume\\OneDrive\\Documents\\WORK M\\Pomatorhinus ruficollis',\n",
    "    'Arborophila torqueola': r'C:\\Users\\soume\\OneDrive\\Documents\\WORK M\\Arborophila torqueola',\n",
    "    'Macronus gularis': r'C:\\Users\\soume\\OneDrive\\Documents\\WORK M\\Macronus gularis'\n",
    "}\n",
    "spectrogram_dir = r'C:\\Users\\soume\\OneDrive\\Documents\\WORK M\\spectrograms'\n",
    "\n",
    "# Initialize and train classifier\n",
    "classifier = AudioSpectrogramClassifier(data_dirs, spectrogram_dir)\n",
    "classifier.train_classifier(epochs=5, use_xgboost=True)\n",
    "\n",
    "# Initialize Dash app with layout\n",
    "app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "app.layout = dbc.Container([\n",
    "    dbc.Row(dbc.Col(html.H1(\"Bird Species Classification from Audio\", className=\"text-center\"), width=12)),\n",
    "    dcc.Tabs([\n",
    "        dcc.Tab(label=\"Model Performance\", children=[\n",
    "            dcc.Graph(figure=classifier.plot_training_metrics()),\n",
    "            dcc.Graph(figure=classifier.plot_confusion_matrix()),\n",
    "            dcc.Graph(figure=classifier.plot_feature_importance()),\n",
    "            dcc.Graph(figure=classifier.plot_training_data_distribution())\n",
    "        ]),\n",
    "        dcc.Tab(label=\"Audio Visualization\", children=[\n",
    "            html.Label(\"Select Audio File:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='audio-file-dropdown',\n",
    "                options=[{'label': file, 'value': os.path.join(path, file)}\n",
    "                         for label, path in data_dirs.items() for file in os.listdir(path) if file.lower().endswith(('.wav', '.mp3', '.flac'))],\n",
    "                value=list(data_dirs.values())[0]  # Default to the first file\n",
    "            ),\n",
    "            dcc.Graph(id='waveform-plot'),\n",
    "            dcc.Graph(id='spectrogram-plot')\n",
    "        ]),\n",
    "        dcc.Tab(label=\"Feature Distribution\", children=[\n",
    "            dcc.Graph(figure=classifier.plot_feature_distribution())\n",
    "        ]),\n",
    "        dcc.Tab(label=\"Bird Count Prediction\", children=[\n",
    "            dcc.Upload(\n",
    "                id='upload-audio',\n",
    "                children=dbc.Button('Upload Audio File', color=\"primary\"),\n",
    "                multiple=False\n",
    "            ),\n",
    "            html.Div(id='prediction-output', className=\"mt-3\")\n",
    "        ]),\n",
    "        dcc.Tab(label=\"Live Audio Recording\", children=[\n",
    "            dbc.Button(\"Record Audio\", id=\"record-button\", color=\"success\"),\n",
    "            html.Div(id='live-prediction-output', className=\"mt-3\")\n",
    "        ])\n",
    "    ])\n",
    "], fluid=True)\n",
    "\n",
    "# Callback for updating audio visualizations\n",
    "@app.callback(\n",
    "    [Output('waveform-plot', 'figure'), Output('spectrogram-plot', 'figure')],\n",
    "    [Input('audio-file-dropdown', 'value')]\n",
    ")\n",
    "def update_audio_visualizations(selected_audio_file):\n",
    "    waveform_fig = classifier.plot_audio_waveform(selected_audio_file)\n",
    "    spectrogram_fig = classifier.plot_audio_spectrogram(selected_audio_file)\n",
    "    return waveform_fig, spectrogram_fig\n",
    "\n",
    "# Callback for predicting bird count from uploaded audio\n",
    "@app.callback(\n",
    "    Output('prediction-output', 'children'),\n",
    "    [Input('upload-audio', 'contents')]\n",
    ")\n",
    "def update_prediction(uploaded_file):\n",
    "    if uploaded_file is not None:\n",
    "        content_type, content_string = uploaded_file.split(',')\n",
    "        decoded = base64.b64decode(content_string)\n",
    "        audio_path = 'uploaded_audio.wav'\n",
    "\n",
    "        try:\n",
    "            with open(audio_path, 'wb') as f:\n",
    "                f.write(decoded)\n",
    "\n",
    "            predictions = classifier.predict_bird_count(audio_path)\n",
    "            result_text = \"\\n\".join([f\"Time: {timestamp:.2f}s - Predicted Bird: {bird}\" for bird, timestamp in predictions])\n",
    "            return f\"Predicted Bird Counts:\\n{result_text}\" if predictions else \"No birds detected.\"\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during prediction: {e}\")\n",
    "            return \"Error during prediction. Please check the audio file.\"\n",
    "    return \"No audio file uploaded.\"\n",
    "\n",
    "# Callback for live audio recording\n",
    "@app.callback(\n",
    "    Output('live-prediction-output', 'children'),\n",
    " [Input('record-button', 'n_clicks')]\n",
    ")\n",
    "def record_and_predict(n_clicks):\n",
    "    if n_clicks is not None:\n",
    "        # Record audio for 5 seconds\n",
    "        audio_filename = 'live_recording.wav'\n",
    "        classifier.record_audio(duration=5, filename=audio_filename)\n",
    "\n",
    "        # Predict bird count from the recorded audio\n",
    "        predictions = classifier.predict_bird_count(audio_filename)\n",
    "        result_text = \"\\n\".join([f\"Time: {timestamp:.2f}s - Predicted Bird: {bird}\" for bird, timestamp in predictions])\n",
    "        return f\"Predicted Bird Counts:\\n{result_text}\" if predictions else \"No birds detected.\"\n",
    "    return \"Click the button to record audio.\"\n",
    "\n",
    "# Run the Dash app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
